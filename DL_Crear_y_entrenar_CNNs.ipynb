{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL - Crear y entrenar CNNs",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a24lorie/DeepLearningKeras/blob/UIMP/DL_Crear_y_entrenar_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W43vhS-mQCf2",
        "colab_type": "text"
      },
      "source": [
        "# Crear y entrenar CNNs en Keras\n",
        "## Ejemplo de clasificación de imágenes con CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UMTkej-QHKh",
        "colab_type": "text"
      },
      "source": [
        "**NOTA IMPORTANTE**\n",
        "\n",
        "Recuerda que estos notebook están compartidos únicamente con **permisos de lectura**, por tanto no podrás ni ejecutarlos ni modificarlos. Para poder interactuar con el notebook **debes hacer una copia del mismo en tu Drive**, usando la opción correspondiente del menú \"Archivo\" de *Colaboratory*.\n",
        "\n",
        "Recuerda también que si durante la realización de la práctica tienes la sensación de que **el notebook no está funcionando bien**, puedes ir al menú \"Entorno de ejecución\" de *Colaboratory* y \"Reiniciar el entorno de ejecución\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "481imW1oQTY7",
        "colab_type": "text"
      },
      "source": [
        "### 1. Importar librerías\n",
        "Lo primero que vamos a hacer es cargar los módulos necesarios de la librería Keras (The Python Deep Learning library).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9egJT9OQuBt",
        "colab_type": "code",
        "outputId": "74053487-79f6-4fb1-d455-04343fcd631a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSXz38aAQq3v",
        "colab_type": "text"
      },
      "source": [
        "### 2. Preparar datos de entrenamiento\n",
        "En este ejemplo vamos a utilizar un conjunto para clasificación de imágenes denominado **CIFAR10**, que está compuesto por 50.000 imágenes de entrenamiento y 10.000 imágenes de test. Se trata de imágenes en color, de dimensiones espaciales 32x32 y etiquetadas en 10 categorías.\n",
        "\n",
        "*En la web de Keras puedes encontrar otros conjuntos de imágenes disponibles para descarga: * https://keras.io/datasets/\n",
        "\n",
        "El método *ImageDataGenerator()* permite generar batches de imágenes con diferentes técnicas de **data augmentation**, utilizando para ello una serie de parámetros opcionales que **no** se han considerado en este ejemplo.\n",
        "\n",
        "*En la web de Keras puedes encontrar más información sobre este método: * https://keras.io/preprocessing/image/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe4mLOyI6eU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cargamos los datos de CIFAR10 (entrenamiento y test)\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Especificamos el numero de clases y las dimensiones de las imagenes\n",
        "n_classes = 10                # numero de clases\n",
        "img_width = img_height = 32   # dimensiones de la imagen\n",
        "\n",
        "# Convertimos el vector de etiquetas en una matriz binaria para codificar las diferentes clases \n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)\n",
        "\n",
        "# Preparamos los datos, dejando una parte para validación y utilizando normalización (featurewise)\n",
        "val_split = 0.2\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, validation_split=val_split)\n",
        "datagen.fit(x_train)  # calcular los valores para la normalizacion (media, desviación típica)\n",
        "\n",
        "# Generamos los batches con los datos para las tres particiones: entrenamiento, validación y test\n",
        "batch_size = 256\n",
        "data_train = datagen.flow(x_train, y_train, batch_size=batch_size, subset=\"training\")\n",
        "data_dev = datagen.flow(x_train, y_train, batch_size=batch_size, subset=\"validation\")\n",
        "data_test = datagen.flow(x_test, y_test, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rb4CqgQ9pef",
        "colab_type": "text"
      },
      "source": [
        "### 3. Crear una CNN\n",
        "El siguiente paso es crear una sencilla CNN. Para ello utilizaremos las siguientes capas:\n",
        "\n",
        "*   Capa convolucional: *Conv2D(n_filters, kernel_size)*, siendo *n_filters* el número de filtros y *kernel_size* su tamaño. Dos de sus parámetros opcionales son:\n",
        "> * *activation*: 'relu', 'sigmoid', etc. (por defecto, *activation=None*; es decir, no se utiliza función de activación).\n",
        "> * *input_shape*: cuando se utiliza como primera capa del modelo, es necesario indicar las dimensiones del volumen de entrada (imagen).\n",
        "\n",
        "*   Capa max-pooling: *MaxPooling2D()*, por defecto utiliza un tamaño de ventana 2.\n",
        "\n",
        "*   Capa completamente conectada: *Dense(units)*, siendo *units* el número de neuronas. Uno de sus parámetros opcionales es:\n",
        "> * *activation*: 'relu', 'sigmoid', 'softmax', etc.\n",
        "\n",
        "*En la web de Keras puedes encontar información más detallada con todas las capas disponibles y los parámetros de las mismas, además de las diferentes funciones de activación.*\n",
        "\n",
        "**Lee los comentarios del código detenidamente para entender lo que se está haciendo.**\n",
        "\n",
        "Fíjate que la línea **model.summary()** imprime una representación en modo texto de la red y además indica el número de parámetros que se deben aprender en cada capa.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teWaHXx29ad_",
        "colab_type": "code",
        "outputId": "4e2d8b3c-3945-48b3-925e-19439520437b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# Creamos un modelo secuencial, compuesto por una secuencia lineal de capas\n",
        "model = Sequential()\n",
        "\n",
        "# Añadimos dos capas convolucionales de 32 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "model.add(Conv2D(32, 3, activation='relu', input_shape=(img_width,img_height,3)))\n",
        "model.add(Conv2D(32, 3, activation='relu'))\n",
        "# Añadimos una capa max-pooling con tamaño de ventana 2\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# Añadimos dos capas convolucionales de 64 filtros (dimensiones 3x3), con ReLU como función de activación\n",
        "model.add(Conv2D(64, 3, activation='relu'))\n",
        "model.add(Conv2D(64, 3, activation='relu'))\n",
        "# Añadimos una capa max-pooling con tamaño de ventana 2\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# Flatten permite transformar el volumen de entrada en un vector\n",
        "model.add(Flatten())\n",
        "# Añadimos una capa completamente conectada con 512 neuronas, con ReLU como función de activación \n",
        "model.add(Dense(512, activation='relu'))\n",
        "# Añadimos una última capa completamente conectada con 10 neuronas (número de clases) para obtener la salida de la red,\n",
        "# utilizando para ello la función Softmax\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# Imprimimos la representacion en modo texto del modelo \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 890,410\n",
            "Trainable params: 890,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE8uzpl7XxRa",
        "colab_type": "text"
      },
      "source": [
        "### 4. Entrenar una CNN\n",
        "Una vez definida la arquitectura de la CNN, el siguiente paso es entrenar el modelo para buscar los parámetros que hagan mínima la función de pérdida. Para ello utilizaremos el método **fit_generator**, que necesita que le suministremos los datos de entrenamiento y validación, el tamaño del *batch* y el número de *epochs*. \n",
        "\n",
        "Finalmente, podemos evaluar el modelo utilizando el conjunto de test con el método **evaluate_generator**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKdmfceMBAz8",
        "colab_type": "code",
        "outputId": "c87569fe-f342-4b5a-9b37-b227a294fe66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Antes de entrenar el modelo, configuramos el proceso de aprendizaje\n",
        "model.compile(loss='categorical_crossentropy',     # función de pérdida para problemas de clasificación multi-clase\n",
        "              optimizer=optimizers.adam(lr=1e-3),  # optimizador Adam, learning rate (lr)\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entrenamos el modelo con los datos preparados en el punto 2\n",
        "model.fit_generator(data_train,\n",
        "                    epochs=6,  # numero de epochs\n",
        "                    verbose=2,  # muestra informacion del error al finalizar cada epoch\n",
        "                    steps_per_epoch=len(x_train)*(1-val_split)/batch_size,\n",
        "                    validation_data=data_dev,\n",
        "                    validation_steps=len(x_train)*val_split/batch_size)\n",
        "\n",
        "# Por ultimo, podemos evaluar el modelo en el conjunto de test\n",
        "print()\n",
        "test_loss, test_acc = model.evaluate_generator(data_test,\n",
        "                                               steps=len(x_test)/batch_size,\n",
        "                                               verbose=1)\n",
        "print(\"test_loss: %.4f, test_acc: %.4f\" % (test_loss, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/6\n",
            " - 10s - loss: 1.5805 - acc: 0.4302 - val_loss: 1.3019 - val_acc: 0.5343\n",
            "Epoch 2/6\n",
            " - 6s - loss: 1.1426 - acc: 0.5976 - val_loss: 1.0577 - val_acc: 0.6226\n",
            "Epoch 3/6\n",
            " - 6s - loss: 0.9482 - acc: 0.6673 - val_loss: 0.9730 - val_acc: 0.6626\n",
            "Epoch 4/6\n",
            " - 6s - loss: 0.8164 - acc: 0.7162 - val_loss: 0.8888 - val_acc: 0.6960\n",
            "Epoch 5/6\n",
            " - 6s - loss: 0.7000 - acc: 0.7579 - val_loss: 0.8106 - val_acc: 0.7196\n",
            "Epoch 6/6\n",
            " - 6s - loss: 0.5901 - acc: 0.7970 - val_loss: 0.7931 - val_acc: 0.7284\n",
            "\n",
            "40/39 [==============================] - 1s 19ms/step\n",
            "test_loss: 0.8169, test_acc: 0.7230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQU74C3waRkW",
        "colab_type": "text"
      },
      "source": [
        "## 5. Pruebas\n",
        "Puedes probar otras configuraciones del modelo para intentar conseguir mejores resultados, e incluso definir tu propia arquitectura (otra secuencia de capas, diferentes hiperparámetros, etc.).\n",
        "\n",
        "Para utilizar **Dropout** en el entrenamiento, es necesario añadir nuevas capas al modelo: *model.add(Dropout(rate))*, siendo *rate* el porcentaje de neuronas que se desactivan. Prueba, por ejemplo, a añadir una capa Dropout después de cada capa max-pooling.\n",
        "\n",
        "Para generar nuevos ejemplos de entrenamiento utilizando diferentes técnicas de **data augmentation**, puedes utilizar algunos de los parámetros opcionales del método *ImageDataGenerator*.\n",
        "\n"
      ]
    }
  ]
}